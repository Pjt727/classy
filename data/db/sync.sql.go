// Code generated by sqlc. DO NOT EDIT.
// versions:
//   sqlc v1.29.0
// source: sync.sql

package db

import (
	"context"
)

const syncAll = `-- name: SyncAll :many
WITH sync_diffs AS (
    SELECT 
           MAX(sequence) AS sequence, 
           table_name,
           MAX(input_at) AS updated_input_at,
           composite_hash,
           school_id,
           ANY_VALUE(CASE
                    WHEN table_name = 'schools' THEN pk_fields::jsonb
                    ELSE jsonb_set(pk_fields::jsonb, '{school_id}', to_jsonb(school_id), true)
           END) AS updated_pk_fields,
           combined_json(
                    (sync_action, relevant_fields)::sync_change
                    ORDER BY sequence
           ) AS sync_changes
    FROM historic_class_information
    WHERE sequence > $2
    GROUP BY composite_hash, table_name, school_id
)
SELECT sequence::int, table_name, updated_input_at AS input_at, composite_hash, school_id, updated_pk_fields AS pk_fields,
    (sync_changes).sync_action::sync_kind AS sync_action,
    (sync_changes).relevant_fields AS relevant_fields,
    COUNT(*) OVER() AS total_rows
FROM sync_diffs
WHERE (sync_changes).sync_action::sync_kind IS NOT NULL
ORDER BY sequence
LIMIT $1::int
`

type SyncAllParams struct {
	MaxRecords   int32 `json:"max_records"`
	LastSequence int32 `json:"last_sequence"`
}

type SyncAllRow struct {
	Sequence       int32       `json:"sequence"`
	TableName      string      `json:"table_name"`
	InputAt        interface{} `json:"input_at"`
	CompositeHash  string      `json:"composite_hash"`
	SchoolID       string      `json:"school_id"`
	PkFields       interface{} `json:"pk_fields"`
	SyncAction     SyncKind    `json:"sync_action"`
	RelevantFields interface{} `json:"relevant_fields"`
	TotalRows      int64       `json:"total_rows"`
}

func (q *Queries) SyncAll(ctx context.Context, arg SyncAllParams) ([]SyncAllRow, error) {
	rows, err := q.db.Query(ctx, syncAll, arg.MaxRecords, arg.LastSequence)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []SyncAllRow
	for rows.Next() {
		var i SyncAllRow
		if err := rows.Scan(
			&i.Sequence,
			&i.TableName,
			&i.InputAt,
			&i.CompositeHash,
			&i.SchoolID,
			&i.PkFields,
			&i.SyncAction,
			&i.RelevantFields,
			&i.TotalRows,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const syncSchool = `-- name: SyncSchool :many
WITH sync_diffs AS (
    SELECT 
           MAX(sequence) AS sequence, 
           table_name,
           MAX(input_at) AS updated_input_at,
           composite_hash,
           school_id,
           ANY_VALUE(CASE
               WHEN table_name = 'schools' THEN pk_fields::jsonb
               ELSE jsonb_set(pk_fields::jsonb, '{school_id}', to_jsonb(school_id), true)
           END) AS updated_pk_fields,
           combined_json(
                    (sync_action, relevant_fields)::sync_change
                    ORDER BY sequence
           ) AS sync_changes
    FROM historic_class_information
    WHERE sequence > $2
          AND school_id = $3
    GROUP BY composite_hash, table_name, school_id
)
SELECT sequence::int, table_name, updated_input_at AS input_at, composite_hash, school_id, updated_pk_fields AS pk_fields,
    (sync_changes).sync_action::sync_kind AS sync_action,
    (sync_changes).relevant_fields AS relevant_fields,
    COUNT(*) OVER() AS total_rows
FROM sync_diffs
WHERE (sync_changes).sync_action::sync_kind IS NOT NULL
ORDER BY sequence
LIMIT $1::int
`

type SyncSchoolParams struct {
	MaxRecords   int32  `json:"max_records"`
	LastSequence int32  `json:"last_sequence"`
	SchoolID     string `json:"school_id"`
}

type SyncSchoolRow struct {
	Sequence       int32       `json:"sequence"`
	TableName      string      `json:"table_name"`
	InputAt        interface{} `json:"input_at"`
	CompositeHash  string      `json:"composite_hash"`
	SchoolID       string      `json:"school_id"`
	PkFields       interface{} `json:"pk_fields"`
	SyncAction     SyncKind    `json:"sync_action"`
	RelevantFields interface{} `json:"relevant_fields"`
	TotalRows      int64       `json:"total_rows"`
}

func (q *Queries) SyncSchool(ctx context.Context, arg SyncSchoolParams) ([]SyncSchoolRow, error) {
	rows, err := q.db.Query(ctx, syncSchool, arg.MaxRecords, arg.LastSequence, arg.SchoolID)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []SyncSchoolRow
	for rows.Next() {
		var i SyncSchoolRow
		if err := rows.Scan(
			&i.Sequence,
			&i.TableName,
			&i.InputAt,
			&i.CompositeHash,
			&i.SchoolID,
			&i.PkFields,
			&i.SyncAction,
			&i.RelevantFields,
			&i.TotalRows,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const syncTerms = `-- name: SyncTerms :many
WITH 
    included_commons AS (
          SELECT h.historic_composite_hash, h.table_name
          FROM historic_class_information_term_dependencies h
          WHERE h.term_collection_id = ANY($2::TEXT[])
                AND h.school_id = $3
    ),
    sync_diffs AS (
    SELECT 
           MAX(sequence) AS sequence, 
           hc.table_name,
           MAX(input_at) AS updated_input_at,
           hc.composite_hash,
           hc.school_id,
           ANY_VALUE(CASE
               WHEN table_name = 'schools' THEN pk_fields::jsonb
               ELSE jsonb_set(pk_fields::jsonb, '{school_id}', to_jsonb(school_id), true)
           END) AS updated_pk_fields,
           combined_json(
                    (sync_action, relevant_fields)::sync_change
                    ORDER BY sequence
           ) AS sync_changes
    FROM historic_class_information hc
    -- UNNESTS are not supported in sqlc so using json work around
    -- https://github.com/sqlc-dev/sqlc/issues/958 :(
    -- JOIN UNNEST(@term_collection_ids::TEXT[], @term_sequences::INTEGER[]) AS checks(term_collection_id, term_sequence)
    JOIN (
        SELECT
            value ->> 'id' AS term_collection_id,
            (value ->> 'sequence')::INTEGER AS term_sequence
        FROM jsonb_array_elements($4::jsonb)
    ) AS checks
        ON h.sequence > checks.term_sequence AND (
        -- sections / meeting times that are directly in the term
        (pk_fields ? 'term_collection_id' AND pk_fields ->> 'term_collection_id' = checks.term_collection_id)
        -- possible updated data on the school
        OR table_name = 'schools'
        -- possible updated data on the term collection
        OR (table_name = 'term_collections' AND pk_fields ->> 'id' = checks.term_collection_id)
        -- related  
        OR (h.composite_hash, h.table_name) IN (SELECT historic_composite_hash, table_name FROM included_commons)
    )
    WHERE school_id = $3
    GROUP BY hc.composite_hash, hc.table_name, hc.school_id
    )
SELECT sequence::int, table_name, updated_input_at AS input_at, composite_hash, school_id, updated_pk_fields AS pk_fields,
    (sync_changes).sync_action::sync_kind AS sync_action,
    (sync_changes).relevant_fields AS relevant_fields,
    COUNT(*) OVER() AS total_rows
FROM sync_diffs
WHERE (sync_changes).sync_action::sync_kind IS NOT NULL
ORDER BY sequence
LIMIT $1::int
`

type SyncTermsParams struct {
	MaxRecords                  int32    `json:"max_records"`
	TermExclusionCollectionIds  []string `json:"term_exclusion_collection_ids"`
	SchoolID                    string   `json:"school_id"`
	TermCollectionSequencePairs []byte   `json:"term_collection_sequence_pairs"`
}

type SyncTermsRow struct {
	Sequence       int32       `json:"sequence"`
	TableName      string      `json:"table_name"`
	InputAt        interface{} `json:"input_at"`
	CompositeHash  string      `json:"composite_hash"`
	SchoolID       string      `json:"school_id"`
	PkFields       interface{} `json:"pk_fields"`
	SyncAction     SyncKind    `json:"sync_action"`
	RelevantFields interface{} `json:"relevant_fields"`
	TotalRows      int64       `json:"total_rows"`
}

// 1. Get all the sequences that are already covered
// 2. Get all sequences
func (q *Queries) SyncTerms(ctx context.Context, arg SyncTermsParams) ([]SyncTermsRow, error) {
	rows, err := q.db.Query(ctx, syncTerms,
		arg.MaxRecords,
		arg.TermExclusionCollectionIds,
		arg.SchoolID,
		arg.TermCollectionSequencePairs,
	)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []SyncTermsRow
	for rows.Next() {
		var i SyncTermsRow
		if err := rows.Scan(
			&i.Sequence,
			&i.TableName,
			&i.InputAt,
			&i.CompositeHash,
			&i.SchoolID,
			&i.PkFields,
			&i.SyncAction,
			&i.RelevantFields,
			&i.TotalRows,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}
